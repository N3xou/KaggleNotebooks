{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":124833,"databundleVersionId":14702338,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:29:23.699439Z","iopub.execute_input":"2025-12-08T18:29:23.699985Z","iopub.status.idle":"2025-12-08T18:29:23.708133Z","shell.execute_reply.started":"2025-12-08T18:29:23.699953Z","shell.execute_reply":"2025-12-08T18:29:23.707062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train  = pd.read_csv(\"/kaggle/input/binary-classification-of-insurance-cross-selling/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/binary-classification-of-insurance-cross-selling/test.csv\")\ntrain = train.drop(columns='id')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:29:23.709544Z","iopub.execute_input":"2025-12-08T18:29:23.709860Z","iopub.status.idle":"2025-12-08T18:29:58.683306Z","shell.execute_reply.started":"2025-12-08T18:29:23.709830Z","shell.execute_reply":"2025-12-08T18:29:58.682143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" print(train.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:29:58.684208Z","iopub.execute_input":"2025-12-08T18:29:58.684513Z","iopub.status.idle":"2025-12-08T18:29:58.698760Z","shell.execute_reply.started":"2025-12-08T18:29:58.684489Z","shell.execute_reply":"2025-12-08T18:29:58.697737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_features = train.select_dtypes(include=[\"object\"]).columns.tolist()\nnumerical_features = train.select_dtypes(exclude=[\"object\"]).columns.tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:29:58.700737Z","iopub.execute_input":"2025-12-08T18:29:58.701117Z","iopub.status.idle":"2025-12-08T18:29:59.329789Z","shell.execute_reply.started":"2025-12-08T18:29:58.701093Z","shell.execute_reply":"2025-12-08T18:29:59.328885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in categorical_features:\n    plt.figure()\n    train[col].value_counts().plot(kind=\"bar\")\n    plt.title(f\"Count Plot of {col}\")\n    plt.xlabel(col)\n    plt.ylabel(\"Count\")\n    plt.show()\nfor col in numerical_features:\n    plt.figure()\n    plt.hist(train[col], bins=30)\n    plt.title(f\"Distribution of {col}\")\n    plt.xlabel(col)\n    plt.ylabel(\"Frequency\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:29:59.330820Z","iopub.execute_input":"2025-12-08T18:29:59.331110Z","iopub.status.idle":"2025-12-08T18:30:06.562754Z","shell.execute_reply.started":"2025-12-08T18:29:59.331089Z","shell.execute_reply":"2025-12-08T18:30:06.562026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoders = {}\n\nfor col in categorical_features:\n    le = LabelEncoder()\n    train[col] = le.fit_transform(train[col])\n    label_encoders[col] = le","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:30:06.563642Z","iopub.execute_input":"2025-12-08T18:30:06.563968Z","iopub.status.idle":"2025-12-08T18:30:13.491128Z","shell.execute_reply.started":"2025-12-08T18:30:06.563938Z","shell.execute_reply":"2025-12-08T18:30:13.489979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr_matrix = train.corr()\nresponse_corr = corr_matrix[\"Response\"].sort_values(ascending=False)\n#print(response_corr)\nplt.figure(figsize=(12, 9))\nsns.heatmap(\n    corr_matrix,\n    annot=True,\n    fmt=\".2f\",\n    linewidths=0.5\n)\n\nplt.title(\"Correlation Heatmap\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:30:13.492067Z","iopub.execute_input":"2025-12-08T18:30:13.492366Z","iopub.status.idle":"2025-12-08T18:30:19.060027Z","shell.execute_reply.started":"2025-12-08T18:30:13.492337Z","shell.execute_reply":"2025-12-08T18:30:19.059125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(response_corr)\nprint(corr_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:30:19.061023Z","iopub.execute_input":"2025-12-08T18:30:19.061388Z","iopub.status.idle":"2025-12-08T18:30:19.072688Z","shell.execute_reply.started":"2025-12-08T18:30:19.061358Z","shell.execute_reply":"2025-12-08T18:30:19.071706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_engineered_features(df):\n    \"\"\"\n    Create new features based on correlation analysis.\n    \n    Key Insights:\n    - Previously_Insured & Vehicle_Damage: -0.84 correlation (highly complementary)\n    - Age correlates with Vehicle_Age (-0.54), Policy_Sales_Channel (-0.59)\n    - Response strongest with: Vehicle_Damage (0.36), Previously_Insured (-0.35)\n    \"\"\"\n\n    categorical_features = df.select_dtypes(include=[\"object\"]).columns.tolist()\n    for col in categorical_features:\n        le = LabelEncoder()\n        df[col] = le.fit_transform(df[col])\n    df_new = df.copy()\n    \n\n    print(df_new.info())\n    print(\"\\nüìä Creating Engineered Features...\")\n    \n    # Feature 1: Risk Profile Score\n    # Combines the two strongest predictors with opposite effects\n    # Not insured (1) + Vehicle damaged (1) = High interest (score=3)\n    df_new['risk_profile'] = (1 - df['Previously_Insured']) * 2 + df['Vehicle_Damage']\n    print(\"‚úì Created 'risk_profile' - Combines insurance status & vehicle damage\")\n    \n    # Feature 2: New Customer with Damage (Interaction)\n    # This captures the sweet spot: customers who need insurance AND have damage\n    df_new['new_customer_damage'] = (1 - df['Previously_Insured']) * df['Vehicle_Damage']\n    print(\"‚úì Created 'new_customer_damage' - Key interaction term\")\n    \n    # Feature 3: Age-Vehicle Mismatch\n    # Unusual combinations indicate different insurance needs\n    age_norm = (df['Age'] - df['Age'].mean()) / df['Age'].std()\n    vehicle_age_norm = (df['Vehicle_Age'] - df['Vehicle_Age'].mean()) / df['Vehicle_Age'].std()\n    df_new['age_vehicle_mismatch'] = np.abs(age_norm + vehicle_age_norm)\n    print(\"‚úì Created 'age_vehicle_mismatch' - Captures unusual age-vehicle combos\")\n    \n    # Feature 4: Customer Maturity Index\n    # Sophisticated customers behave differently\n    df_new['customer_maturity'] = (\n        (df['Age'] / 100) * 0.5 +\n        df['Previously_Insured'] * 0.3 +\n        (df['Policy_Sales_Channel'] / df['Policy_Sales_Channel'].max()) * 0.2\n    )\n    print(\"‚úì Created 'customer_maturity' - Overall customer sophistication score\")\n    \n    # Feature 5: Premium Affordability by Age\n    # Context matters - same premium means different things at different ages\n    df_new['premium_age_ratio'] = df['Annual_Premium'] / (df['Age'] + 1)\n    print(\"‚úì Created 'premium_age_ratio' - Premium affordability metric\")\n    \n    # Feature 6: Channel-Age Interaction\n    # Different channels work better for different age groups (-0.59 correlation)\n    df_new['channel_age_interaction'] = df['Policy_Sales_Channel'] * (100 - df['Age']) / 100\n    print(\"‚úì Created 'channel_age_interaction' - Age-specific channel effectiveness\")\n    \n    # Feature 7: Vehicle Risk Score\n    # Old damaged vehicles have different insurance appeal\n    df_new['vehicle_risk_score'] = df['Vehicle_Age'] * 0.5 + df['Vehicle_Damage'] * 0.5\n    print(\"‚úì Created 'vehicle_risk_score' - Combined vehicle risk indicator\")\n    \n    # Feature 8: Premium Vintage Ratio\n    # How premium relates to customer tenure\n    df_new['premium_vintage_ratio'] = df['Annual_Premium'] / (df['Vintage'] + 1)\n    print(\"‚úì Created 'premium_vintage_ratio' - Premium per tenure period\")\n    \n    # Feature 9: High-Value Prospect Flag\n    # Binary flag for ideal customer profile\n    df_new['high_value_prospect'] = (\n        (df['Vehicle_Damage'] == 1) &\n        (df['Previously_Insured'] == 0) &\n        (df['Age'] > 30) &\n        (df['Annual_Premium'] > df['Annual_Premium'].median())\n    ).astype(int)\n    print(\"‚úì Created 'high_value_prospect' - Ideal customer flag\")\n    \n    # Feature 10: Gender-Age Interaction\n    df_new['gender_age_interaction'] = df['Gender'] * (df['Age'] / 100)\n    print(\"‚úì Created 'gender_age_interaction' - Gender effect by age\")\n    \n    print(f\"\\n‚úÖ Total features: {len(df_new.columns)} (added {len(df_new.columns) - len(df.columns)} new features)\")\n    \n    return df_new","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T20:02:54.591218Z","iopub.execute_input":"2025-12-08T20:02:54.591560Z","iopub.status.idle":"2025-12-08T20:02:54.603582Z","shell.execute_reply.started":"2025-12-08T20:02:54.591538Z","shell.execute_reply":"2025-12-08T20:02:54.602492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:30:19.094513Z","iopub.execute_input":"2025-12-08T18:30:19.094785Z","iopub.status.idle":"2025-12-08T18:30:19.114066Z","shell.execute_reply.started":"2025-12-08T18:30:19.094762Z","shell.execute_reply":"2025-12-08T18:30:19.113041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train.drop('Response', axis=1)\ny = train['Response']\n\n# Engineer features\nX = create_engineered_features(X)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:30:19.115053Z","iopub.execute_input":"2025-12-08T18:30:19.115405Z","iopub.status.idle":"2025-12-08T18:30:40.887616Z","shell.execute_reply.started":"2025-12-08T18:30:19.115373Z","shell.execute_reply":"2025-12-08T18:30:40.886474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_and_train_ensemble(X_train, y_train):\n    \n    # Model 1: XGBoost - Great for capturing complex patterns\n    pos_count = (y_train == 1).sum()\n    neg_count = (y_train == 0).sum()\n    scale_pos_weight = neg_count / pos_count\n    print(\"\\nüîß Initializing XGBoost...\")\n    xgb_model = XGBClassifier(\n        n_estimators=5000,\n        max_depth=12,\n        learning_rate=0.1,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        random_state=42,\n        scale_pos_weight=scale_pos_weight,\n        eval_metric='logloss',\n        use_label_encoder=False\n    )\n    \n    # Model 2: Random Forest - Robust and interpretable\n    print(\"üîß Initializing Random Forest...\")\n    rf_model = RandomForestClassifier(\n        n_estimators=5000,\n        max_depth=6,\n        min_samples_split=20,\n        min_samples_leaf=10,\n        class_weight='balanced',\n        random_state=42,\n        n_jobs=-1\n    )\n    \n    # Ensemble: Voting Classifier with soft voting (probability averaging)\n    print(\"üîß Creating Voting Ensemble...\")\n    ensemble = VotingClassifier(\n        estimators=[\n            ('xgb', xgb_model),\n            ('rf', rf_model)\n        ],\n        voting='soft',\n        weights=[0.7 , 0.3], \n        n_jobs=-1\n    )\n    \n    # Train the ensemble\n    print(\"\\nüöÄ Training ensemble model...\")\n    ensemble.fit(X_train, y_train)\n    print(\"‚úÖ Training complete!\")\n    \n    return ensemble\ndef evaluate_model(ensemble, X_train, X_test, y_train, y_test):\n    \"\"\"\n    Comprehensive model evaluation with visualizations.\n    \"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"MODEL EVALUATION\")\n    print(\"=\" * 80)\n    \n    # Predictions\n    y_pred_train = ensemble.predict(X_train)\n    y_pred_test = ensemble.predict(X_test)\n    y_pred_proba_train = ensemble.predict_proba(X_train)[:, 1]\n    y_pred_proba_test = ensemble.predict_proba(X_test)[:, 1]\n    \n    # Performance metrics\n    print(\"\\nüìà TRAINING SET PERFORMANCE:\")\n    print(f\"ROC-AUC Score: {roc_auc_score(y_train, y_pred_proba_train):.4f}\")\n    \n    print(\"\\nüìä TESTING SET PERFORMANCE:\")\n    print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba_test):.4f}\")\n    \n    print(\"\\nüìã Classification Report (Test Set):\")\n    print(classification_report(y_test, y_pred_test))\n    \n    print(\"\\nüî¢ Confusion Matrix (Test Set):\")\n    cm = confusion_matrix(y_test, y_pred_test)\n    print(cm)\n    \n    # Visualization 1: Confusion Matrix\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n    axes[0].set_title('Confusion Matrix (Test Set)', fontsize=14, fontweight='bold')\n    axes[0].set_ylabel('True Label')\n    axes[0].set_xlabel('Predicted Label')\n    \n    # Visualization 2: ROC Curve\n    fpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\n    auc_score = roc_auc_score(y_test, y_pred_proba_test)\n    \n    axes[1].plot(fpr, tpr, label=f'Ensemble (AUC = {auc_score:.4f})', linewidth=2)\n    axes[1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n    axes[1].set_xlabel('False Positive Rate')\n    axes[1].set_ylabel('True Positive Rate')\n    axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return y_pred_proba_test\n\n\ndef plot_feature_importance(ensemble, feature_names):\n    \"\"\"\n    Plot feature importance from both models.\n    \"\"\"\n    print(\"\\n\" + \"=\" * 80)\n    print(\"FEATURE IMPORTANCE ANALYSIS\")\n    print(\"=\" * 80)\n    \n    # Extract models from ensemble\n    xgb_model = ensemble.named_estimators_['xgb']\n    rf_model = ensemble.named_estimators_['rf']\n    \n    # Get feature importances\n    xgb_importance = xgb_model.feature_importances_\n    rf_importance = rf_model.feature_importances_\n    \n    # Create DataFrame\n    importance_df = pd.DataFrame({\n        'Feature': feature_names,\n        'XGBoost': xgb_importance,\n        'RandomForest': rf_importance,\n        'Average': xgb_importance * 0.6 + rf_importance * 0.4\n    }).sort_values('Average', ascending=False)\n    \n    print(\"\\nüèÜ Top 15 Most Important Features:\")\n    print(importance_df.head(15).to_string(index=False))\n    \n    # Visualization\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    \n    # Top 10 features\n    top_features = importance_df.head(10)\n    \n    # XGBoost importance\n    axes[0].barh(range(len(top_features)), top_features['XGBoost'], color='#1f77b4')\n    axes[0].set_yticks(range(len(top_features)))\n    axes[0].set_yticklabels(top_features['Feature'])\n    axes[0].invert_yaxis()\n    axes[0].set_xlabel('Importance Score')\n    axes[0].set_title('XGBoost Feature Importance (Top 10)', fontsize=12, fontweight='bold')\n    axes[0].grid(True, alpha=0.3)\n    \n    # Random Forest importance\n    axes[1].barh(range(len(top_features)), top_features['RandomForest'], color='#2ca02c')\n    axes[1].set_yticks(range(len(top_features)))\n    axes[1].set_yticklabels(top_features['Feature'])\n    axes[1].invert_yaxis()\n    axes[1].set_xlabel('Importance Score')\n    axes[1].set_title('Random Forest Feature Importance (Top 10)', fontsize=12, fontweight='bold')\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return importance_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:30:40.888705Z","iopub.execute_input":"2025-12-08T18:30:40.888956Z","iopub.status.idle":"2025-12-08T18:30:40.908560Z","shell.execute_reply.started":"2025-12-08T18:30:40.888935Z","shell.execute_reply":"2025-12-08T18:30:40.907618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ensemble_model = build_and_train_ensemble(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T18:30:40.909532Z","iopub.execute_input":"2025-12-08T18:30:40.909945Z","iopub.status.idle":"2025-12-08T19:38:22.573179Z","shell.execute_reply.started":"2025-12-08T18:30:40.909913Z","shell.execute_reply":"2025-12-08T19:38:22.571431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_proba_test = evaluate_model(ensemble_model, X_train, X_test, y_train, y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T19:38:22.576271Z","iopub.execute_input":"2025-12-08T19:38:22.576828Z","iopub.status.idle":"2025-12-08T19:53:19.115641Z","shell.execute_reply.started":"2025-12-08T19:38:22.576792Z","shell.execute_reply":"2025-12-08T19:53:19.114697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_names = X.columns.tolist()\nimportance_df = plot_feature_importance(ensemble_model, feature_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T19:53:19.116937Z","iopub.execute_input":"2025-12-08T19:53:19.117321Z","iopub.status.idle":"2025-12-08T19:53:19.679778Z","shell.execute_reply.started":"2025-12-08T19:53:19.117265Z","shell.execute_reply":"2025-12-08T19:53:19.678690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\nprint(\"=\" * 80)\nprint(\"SUBMISSION FILE GENERATOR\")\nprint(\"=\" * 80)\n\n# ============================================================================\n# FUNCTION: CREATE SUBMISSION FILE\n# ============================================================================\n\ndef create_submission_file(test_data, model, id_column='id', \n                          filename='submission.csv', \n                          feature_engineer_func=None):\n    \"\"\"\n    Create a submission file with predictions on test data.\n    \n    Parameters:\n    -----------\n    test_data : DataFrame\n        Test dataset containing features and id column\n    model : trained model\n        Your trained ensemble model (or any sklearn-compatible model)\n    id_column : str\n        Name of the ID column in test data (default: 'id')\n    filename : str\n        Name for the output CSV file\n    feature_engineer_func : function\n        Function to apply feature engineering (same as training)\n    \n    Returns:\n    --------\n    submission_df : DataFrame\n        Submission dataframe with id and Response probability\n    \"\"\"\n    \n    print(f\"\\nüìã Creating submission file...\")\n    print(f\"   Test data shape: {test_data.shape}\")\n    \n    # Step 1: Extract IDs\n    if id_column not in test_data.columns:\n        raise ValueError(f\"ID column '{id_column}' not found in test data!\")\n    \n    test_ids = test_data[id_column].copy()\n    print(f\"   ‚úì Extracted {len(test_ids):,} IDs\")\n    \n    # Step 2: Prepare features (drop ID column)\n    X_test = test_data.drop(columns=[id_column])\n    print(f\"   ‚úì Prepared features: {X_test.shape[1]} columns\")\n    \n    # Step 3: Apply feature engineering if provided\n    if feature_engineer_func is not None:\n        print(f\"   üîß Applying feature engineering...\")\n        X_test = feature_engineer_func(X_test)\n        print(f\"   ‚úì Engineered features: {X_test.shape[1]} columns\")\n    \n    # Step 4: Generate predictions (probabilities for class 1)\n    print(f\"   üîÆ Generating predictions...\")\n    predictions = model.predict_proba(X_test)[:, 1]\n    print(f\"   ‚úì Generated {len(predictions):,} predictions\")\n    \n    # Step 5: Create submission dataframe\n    submission_df = pd.DataFrame({\n        id_column: test_ids,\n        'Response': predictions\n    })\n    \n    # Step 6: Validate submission format\n    print(f\"\\nüìä Submission Statistics:\")\n    print(f\"   Total predictions: {len(submission_df):,}\")\n    print(f\"   Min probability: {predictions.min():.6f}\")\n    print(f\"   Max probability: {predictions.max():.6f}\")\n    print(f\"   Mean probability: {predictions.mean():.6f}\")\n    print(f\"   Median probability: {np.median(predictions):.6f}\")\n    \n    # Check for any issues\n    if submission_df[id_column].duplicated().any():\n        print(f\"   ‚ö†Ô∏è  WARNING: Duplicate IDs found!\")\n    if submission_df['Response'].isna().any():\n        print(f\"   ‚ö†Ô∏è  WARNING: NaN values in predictions!\")\n    if (predictions < 0).any() or (predictions > 1).any():\n        print(f\"   ‚ö†Ô∏è  WARNING: Predictions outside [0, 1] range!\")\n    \n    # Step 7: Save to CSV\n    submission_df.to_csv(filename, index=False)\n    print(f\"\\n‚úÖ Submission file saved: '{filename}'\")\n    \n    # Step 8: Display preview\n    print(f\"\\nüìÑ Preview of submission file:\")\n    print(\"-\" * 50)\n    print(submission_df.head(10))\n    print(\"...\")\n    print(submission_df.tail(5))\n    \n    return submission_df\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T19:53:19.681027Z","iopub.execute_input":"2025-12-08T19:53:19.681928Z","iopub.status.idle":"2025-12-08T19:53:19.696277Z","shell.execute_reply.started":"2025-12-08T19:53:19.681902Z","shell.execute_reply":"2025-12-08T19:53:19.695124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/binary-classification-of-insurance-cross-selling/test.csv\")\nsubmission = create_submission_file(test_data, ensemble_model, id_column='id', \n                          filename='submission.csv', \n                          feature_engineer_func=create_engineered_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T20:03:00.239793Z","iopub.execute_input":"2025-12-08T20:03:00.240130Z","iopub.status.idle":"2025-12-08T20:08:32.778400Z","shell.execute_reply.started":"2025-12-08T20:03:00.240106Z","shell.execute_reply":"2025-12-08T20:08:32.777380Z"}},"outputs":[],"execution_count":null}]}