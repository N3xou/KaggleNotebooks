{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:04:28.789956Z","iopub.execute_input":"2025-05-11T17:04:28.790273Z","iopub.status.idle":"2025-05-11T17:04:29.209041Z","shell.execute_reply.started":"2025-05-11T17:04:28.790250Z","shell.execute_reply":"2025-05-11T17:04:29.207422Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n# Load your dataset\ntrain_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:09:28.047543Z","iopub.execute_input":"2025-05-11T17:09:28.047913Z","iopub.status.idle":"2025-05-11T17:09:30.291062Z","shell.execute_reply.started":"2025-05-11T17:09:28.047845Z","shell.execute_reply":"2025-05-11T17:09:30.290164Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df_pred = test_df[[\"id\"]].copy()\ndf_pred[\"winner_model_a\"] = 1/3\ndf_pred[\"winner_model_b\"] = 1/3\ndf_pred[\"winner_tie\"] = 1/3\n#df_pred.to_csv(\"submission.csv\", index=False)\nprint(df_pred.head())\nprint(df_pred.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:09:46.985715Z","iopub.execute_input":"2025-05-11T17:09:46.986201Z","iopub.status.idle":"2025-05-11T17:09:47.002260Z","shell.execute_reply.started":"2025-05-11T17:09:46.986163Z","shell.execute_reply":"2025-05-11T17:09:47.001103Z"}},"outputs":[{"name":"stdout","text":"        id  winner_model_a  winner_model_b  winner_tie\n0   136060        0.333333        0.333333    0.333333\n1   211333        0.333333        0.333333    0.333333\n2  1233961        0.333333        0.333333    0.333333\nid                  int64\nwinner_model_a    float64\nwinner_model_b    float64\nwinner_tie        float64\ndtype: object\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Sum each target column\nlabel_counts = {\n    \"winner_model_a\": train_df[\"winner_model_a\"].sum(),\n    \"winner_model_b\": train_df[\"winner_model_b\"].sum(),\n    \"winner_tie\": train_df[\"winner_tie\"].sum()\n}\n\n# Total number of rows in training set\ntotal = len(train_df)\n\n# Convert to probabilities\nlabel_probs = {k: v / total for k, v in label_counts.items()}\nprint(\"Training Label Probabilities:\", label_probs)\n\n# Create prediction DataFrame using test IDs\npred_df = test_df[[\"id\"]].copy()\npred_df[\"winner_model_a\"] = label_probs[\"winner_model_a\"]\npred_df[\"winner_model_b\"] = label_probs[\"winner_model_b\"]\npred_df[\"winner_tie\"] = label_probs[\"winner_tie\"]\n\n# Save predictions\npred_df.to_csv(\"submission.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:10:47.155665Z","iopub.execute_input":"2025-05-11T17:10:47.156043Z","iopub.status.idle":"2025-05-11T17:10:47.171209Z","shell.execute_reply.started":"2025-05-11T17:10:47.156019Z","shell.execute_reply":"2025-05-11T17:10:47.169641Z"}},"outputs":[{"name":"stdout","text":"Training Label Probabilities: {'winner_model_a': 0.34907876193955845, 'winner_model_b': 0.341910677314404, 'winner_tie': 0.30901056074603755}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}